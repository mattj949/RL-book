{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecaf7433-f474-4a09-bbca-bb8e280e8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.monte_carlo import *\n",
    "from rl.td import *\n",
    "from rl.function_approx import Tabular\n",
    "from rl.distribution import Constant\n",
    "import rl.iterate as iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bdfabc-13e0-45d8-8c5e-3505ae277499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for estimating the value function\n",
    "# Traces is an iterable of trace experiences\n",
    "# A trace experience is an iterable of atomic experiences\n",
    "# An atomic experience is a TransitionStep[S], which contains\n",
    "# the current state, next state, and reward\n",
    "def tabular_mc_prediction(\n",
    "    traces: Iterable[Iterable[mp.TransitionStep[S]]],\n",
    "    tab_0: Tabular[S],\n",
    "    γ: float,\n",
    "    episode_length_tolerance: float = 1e-6\n",
    ") -> Iterator[Tabular[S]]:\n",
    "    \n",
    "    '''\n",
    "    Returns: Produces as output an Iterator of\n",
    "    Tabular[S], i.e. an updated function approximation\n",
    "    of the Value function at the end of each trace \n",
    "    experience. The updates can only be done at the end\n",
    "    of trace experiences because trace experience returns\n",
    "    are only available at the end of trace experiences.\n",
    "    '''\n",
    "    \n",
    "    # Calculate returns for each trace experience. Recall that for \n",
    "    # mc, we can only do this at the end of the experience, unless\n",
    "    # gamma < 1, in which case we can run through a trace experience\n",
    "    # until the return converges (rewards farther and farther in the future\n",
    "    # becomes less and less valuable today; at a certain point we can just \n",
    "    # ignore future rewards and go ahead and calculate the value function. \n",
    "    \n",
    "    # returns will calculate return for a given state given the future returns\n",
    "    # that are \"relevant\" considering our gamma discount factor\n",
    "    \n",
    "    # ReturnStep is just a dataclass with a single attribute: return\n",
    "    # It inherets from TransitionStep which has, as attributes:\n",
    "    # state, next_state, reward\n",
    "    episodes: Iterator[Iterator[mp.ReturnStep[S]]] = \\\n",
    "        (returns(trace, γ, episode_length_tolerance) for trace in traces)\n",
    "    f = tab_0\n",
    "    yield f\n",
    "    \n",
    "    \n",
    "    # iterate_updates calls the method update of FunctionApprox\n",
    "    # for a single (state, return) data point. \n",
    "    for episode in episodes:\n",
    "        f = last(f.iterate_updates(\n",
    "            [(step.state, step.return_)] for step in episode\n",
    "        ))\n",
    "        yield f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5b933b-7d24-47e3-90b0-433d92a018f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular td does not take trace experiences as input,\n",
    "# but just takes a single trace experience, which is an\n",
    "# iterable of atomic experiences (aka TransitionSteps)\n",
    "\n",
    "def tabular_td_prediction(\n",
    "        transitions: Iterable[mp.TransitionStep[S]],\n",
    "        approx_0: Tabular[S],\n",
    "        γ: float\n",
    ") -> Iterator[Tabular[S]]:\n",
    "    '''Evaluate an MRP using TD(0) using the given sequence of\n",
    "    transitions.\n",
    "\n",
    "    Each value this function yields represents the approximated value\n",
    "    function for the MRP after an additional transition.\n",
    "\n",
    "    Arguments:\n",
    "      transitions -- a sequence of transitions from an MRP which don't\n",
    "                     have to be in order or from the same simulation\n",
    "      approx_0 -- initial approximation of value function\n",
    "      γ -- discount rate (0 < γ ≤ 1)\n",
    "\n",
    "    '''\n",
    "    def step(\n",
    "            v: Tabular[S],\n",
    "            transition: mp.TransitionStep[S]\n",
    "    ) -> Tabular[S]:\n",
    "        return v.update([(\n",
    "            transition.state,\n",
    "            transition.reward + γ * extended_vf(v, transition.next_state)\n",
    "        )])\n",
    "    return iterate.accumulate(transitions, step, initial=approx_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7202b18-dedc-4f39-9b3c-30441389dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.chapter2.simple_inventory_mrp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4ee026-5f6d-45e2-88ca-18aaef5dd90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_capacity = 2\n",
    "user_poisson_lambda = 1.0\n",
    "user_holding_cost = 1.0\n",
    "user_stockout_cost = 10.0\n",
    "\n",
    "user_gamma = 0.9\n",
    "\n",
    "si_mrp = SimpleInventoryMRPFinite(\n",
    "    capacity=user_capacity,\n",
    "    poisson_lambda=user_poisson_lambda,\n",
    "    holding_cost=user_holding_cost,\n",
    "    stockout_cost=user_stockout_cost\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01474178-1d85-441f-891c-b5c4a9fadd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function\n",
      "--------------\n",
      "{NonTerminal(state=InventoryState(on_hand=0, on_order=0)): -35.511,\n",
      " NonTerminal(state=InventoryState(on_hand=0, on_order=1)): -27.932,\n",
      " NonTerminal(state=InventoryState(on_hand=0, on_order=2)): -28.345,\n",
      " NonTerminal(state=InventoryState(on_hand=1, on_order=0)): -28.932,\n",
      " NonTerminal(state=InventoryState(on_hand=1, on_order=1)): -29.345,\n",
      " NonTerminal(state=InventoryState(on_hand=2, on_order=0)): -30.345}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Correct Value Function:\n",
    "\n",
    "print(\"Value Function\")\n",
    "print(\"--------------\")\n",
    "si_mrp.display_value_function(gamma=user_gamma)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ce781b-447a-421b-a4b7-d1eeca944ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Value Function: \n",
    "\n",
    "# 1) Create a tabular value function approximation\n",
    "# 2) Generate an iterable of trace experiences via simulation\n",
    "# 3) Run thse trace experiences through the update function of tabular_mc_prediction\n",
    "# 4) Display the value function\n",
    "\n",
    "# If we continue the inventory MRP long enough, we will fully explore\n",
    "# the state-space, so there isn't a need to create different starting \n",
    "# states.\n",
    "dist = Constant(NonTerminal(InventoryState(0,0)))\n",
    "trace_experiences = si_mrp.reward_traces(dist)\n",
    "\n",
    "# num = 0\n",
    "# for trace in trace_experiences:\n",
    "#     #print(trace)\n",
    "#     #print(list(trace))\n",
    "#     for atomic in trace:\n",
    "#         print(\"printing atomic experiences\")\n",
    "#         print(atomic)\n",
    "#         num += 1\n",
    "#         if num > 5:\n",
    "#             break\n",
    "#     if num > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db4cd4f-e571-415f-b85f-498f61bf6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_approx = Tabular()\n",
    "value_functs_mc = tabular_mc_prediction(trace_experiences, mc_approx, user_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5613e77-23bc-41a6-ae27-174ea70cee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num = 0\n",
    "num_iterations = 50\n",
    "processed_value_funcs_mc = []\n",
    "for i in value_functs_mc:\n",
    "    processed_value_funcs_mc += [i]\n",
    "    v_num += 1\n",
    "    if v_num > num_iterations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559f83d5-c68f-4121-afb0-712c59bb17e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tabular(values_map={NonTerminal(state=InventoryState(on_hand=0, on_order=0)): -35.79894911892993, NonTerminal(state=InventoryState(on_hand=0, on_order=2)): -28.655573084226816, NonTerminal(state=InventoryState(on_hand=2, on_order=0)): -30.41939743807319, NonTerminal(state=InventoryState(on_hand=1, on_order=0)): -29.11111644956282, NonTerminal(state=InventoryState(on_hand=0, on_order=1)): -27.906045691477633, NonTerminal(state=InventoryState(on_hand=1, on_order=1)): -29.574156634917447}, counts_map={NonTerminal(state=InventoryState(on_hand=0, on_order=0)): 826, NonTerminal(state=InventoryState(on_hand=0, on_order=2)): 819, NonTerminal(state=InventoryState(on_hand=2, on_order=0)): 1074, NonTerminal(state=InventoryState(on_hand=1, on_order=0)): 1053, NonTerminal(state=InventoryState(on_hand=0, on_order=1)): 1743, NonTerminal(state=InventoryState(on_hand=1, on_order=1)): 1035}, count_to_weight_func=<function Tabular.<lambda>.<locals>.<lambda> at 0x7fee589015e0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_value_funcs_mc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5efc5-6231-4b6d-bc5d-116f65829371",
   "metadata": {},
   "source": [
    "## We see that the tabular_mc_prediction's value function after 50 iterations has converged to the true value function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32135ff4-005d-44e1-9189-a0a4c1020f6d",
   "metadata": {},
   "source": [
    "# TD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c5e0b14-d580-46d0-a2d1-33eb67b292cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Constant(NonTerminal(InventoryState(0,0)))\n",
    "trace_experiences = si_mrp.simulate_reward(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefc8ee1-0f02-449e-ad4d-e0d618b13045",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_approx = Tabular()\n",
    "value_functs_td = tabular_td_prediction(trace_experiences, td_approx, user_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b825cb-1a8c-4d32-855b-64a0ef27ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_num = 0\n",
    "num_iterations = 50\n",
    "processed_value_funcs_td = []\n",
    "for i in value_functs_td:\n",
    "    processed_value_funcs_td += [i]\n",
    "    v_num += 1\n",
    "    if v_num > num_iterations:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be046189-0da7-4e43-8c17-c6d5f931baab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tabular(values_map={NonTerminal(state=InventoryState(on_hand=0, on_order=0)): -12.426004427757956, NonTerminal(state=InventoryState(on_hand=0, on_order=2)): -6.371269188338848, NonTerminal(state=InventoryState(on_hand=1, on_order=0)): -10.0941843355077, NonTerminal(state=InventoryState(on_hand=1, on_order=1)): -10.166434361915814, NonTerminal(state=InventoryState(on_hand=2, on_order=0)): -3.573091497054298, NonTerminal(state=InventoryState(on_hand=0, on_order=1)): -12.205731115672087}, counts_map={NonTerminal(state=InventoryState(on_hand=0, on_order=0)): 9, NonTerminal(state=InventoryState(on_hand=0, on_order=2)): 9, NonTerminal(state=InventoryState(on_hand=1, on_order=0)): 10, NonTerminal(state=InventoryState(on_hand=1, on_order=1)): 9, NonTerminal(state=InventoryState(on_hand=2, on_order=0)): 5, NonTerminal(state=InventoryState(on_hand=0, on_order=1)): 8}, count_to_weight_func=<function Tabular.<lambda>.<locals>.<lambda> at 0x7fee7816d430>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_value_funcs_td[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d4a29-9aa2-4089-a60a-600d16341bbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Not converging... or at least converging very slowly. We know that TD is biased, but much lower variance. We might be seeing that bias here, and it is quite servere.\n",
    "\n",
    "## Reminder: MC is lower bias but higher variance, but TD is higher bias and lower variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0905bc-b3be-4bdb-b655-77554e184350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
